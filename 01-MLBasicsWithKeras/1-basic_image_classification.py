#! -*- coding:utf-8 -*-
# 基本图像分类
# 本指南将训练一个神经网络模型, 对运动鞋和衬衫等服装图像进行分类
# https://tensorflow.google.cn/tutorials/keras/classification

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

# 引入mnist数据集
# mnist: MNIST数据集(Mixed National Institute of Standards and Technology database)
# 是美国国家标准与技术研究院收集整理的大型手写数字数据库, 包含60000个示例的训练集以及10000个示例的测试集
(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()

# 每个图像都会被映射到一个标签
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# 观察训练数据集图片形状以及对应标签分类
print(train_images.shape)
print(train_labels)

# 将这些值缩小至 0 到 1 之间, 然后将其馈送到神经网络模型
# 为此, 请将这些值除以 255. 请务必以相同的方式对训练集和测试集进行预处理
train_images, test_images = train_images / 255.0, test_images / 255.0

# 为了验证数据的格式是否正确, 以及您是否已准备好构建和训练网络, 让我们显示训练集中的前 25 个图像, 并在每个图像下方显示类名称
plt.figure(figsize=(10, 10))
for i in range(25):
    plt.subplot(5, 5, i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
plt.show()

# 该网络的第一层 tf.keras.layers.Flatten 将图像格式从二维数组（28 x 28 像素）转换成一维数组（28 x 28 = 784 像素）。
# 将该层视为图像中未堆叠的像素行并将其排列起来. 该层没有要学习的参数, 它只会重新格式化数据
# 展平像素后, 网络会包括两个 tf.keras.layers.Dense 层的序列。它们是密集连接或全连接神经层
# 第一个 Dense 层有 128 个节点（或神经元）
# 第二个（也是最后一个）层会返回一个长度为 10 的 logits 数组. 每个节点都包含一个得分, 用来表示当前图像属于 10 个类中的哪一类
# 激活函数 relu 将保留线性有效部分
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10)
])
model.summary()

# 损失函数 - 用于测量模型在训练期间的准确率. 您会希望最小化此函数, 以便将模型“引导”到正确的方向上
# 优化器 - 决定模型如何根据其看到的数据和自身的损失函数进行更新
# 指标 - 用于监控训练和测试步骤. 以下示例使用了准确率, 即被正确分类的图像的比率
# optimizer 优化函数 这里采用梯度下降优化算法
# loss 损失函数 sparse_categorical_crossentropy
# 计算标签和预测之间的交叉熵损失
# 有两个或多个标签类别时, 请使用此交叉熵损失函数
# 我们希望标签以整数形式提供. 如果要使用one-hot表示形式提供标签, 请使用CategoricalCrossentropy损失
# metrics 指标显示 准确率（accuracy）
model.compile(optimizer="adam", loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=["accuracy"])

# 将训练数据集以及对应的标签添加到模型中训练
# epochs 训练的次数
model.fit(train_images, train_labels, epochs=10)

# 比较模型在测试数据集上的表现
test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)
print('\nTest accuracy:', test_acc)

# 在模型经过训练后, 您可以使用它对一些图像进行预测
# 模型具有线性输出, 即 logits. 您可以附加一个 softmax 层, 将 logits 转换成更容易理解的概率
probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])

predictions = probability_model.predict(test_images)

# 打印预测结果
print(predictions[0])

# 预测结果是一个包含 10 个数字的数组. 它们代表模型对 10 种不同服装中每种服装的“置信度”. 您可以看到哪个标签的置信度值最大
print(np.argmax(predictions[0]))

# 同时输入图像对应的真实标签 与预测的标签对比
print(test_labels[0])

# 输出预测的这个图像
# plt.figure()
# plt.imshow(test_images[0])
# plt.colorbar()
# plt.grid(False)
# plt.show()


# 您可以将其绘制成图表, 看看模型对于全部 10 个类的预测
def plot_image(i, predictions_array, true_label, img):
    predictions_array, true_label, img = predictions_array, true_label[i], img[i]
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(img, cmap=plt.cm.binary)
    predicted_label = np.argmax(predictions_array)
    if predicted_label == true_label:
        color = 'blue'
    else:
        color = 'red'
    plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label], 100*np.max(predictions_array), class_names[true_label]), color=color)


def plot_value_array(i, predictions_array, true_label):
    predictions_array, true_label = predictions_array, true_label[i]
    plt.grid(False)
    plt.xticks(range(10))
    plt.yticks([])
    thisplot = plt.bar(range(10), predictions_array, color="#777777")
    plt.ylim([0, 1])
    predicted_label = np.argmax(predictions_array)
    thisplot[predicted_label].set_color('red')
    thisplot[true_label].set_color('blue')


i = 0
plt.figure(figsize=(6, 3))
plt.subplot(1, 2, 1)
plot_image(i, predictions[i], test_labels, test_images)
plt.subplot(1, 2, 2)
plot_value_array(i, predictions[i],  test_labels)
plt.show()


# 绘制第一个X测试图像它们的预测标签和真实标签
# 正确的预测用蓝色表示, 不正确的预测用红色表示
num_rows = 5
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize=(2*2*num_cols, 2*num_rows))
for i in range(num_images):
    plt.subplot(num_rows, 2*num_cols, 2*i+1)
    plot_image(i, predictions[i], test_labels, test_images)
    plt.subplot(num_rows, 2*num_cols, 2*i+2)
    plot_value_array(i, predictions[i], test_labels)
plt.tight_layout()
plt.show()


# tf.keras 模型经过了优化, 可同时对一个批或一组样本进行预测
# 因此, 即便您只使用一个图像, 您也需要将其添加到列表中
img = np.expand_dims(test_images[1], 0)
print(img.shape)
# 现在预测这个图像的正确标签
predictions_single = probability_model.predict(img)
print(predictions_single)
plot_value_array(1, predictions_single[0], test_labels)
_ = plt.xticks(range(10), class_names, rotation=45)
plt.show()
# keras.Model.predict 会返回一组列表, 每个列表对应一批数据中的每个图像. 在批次中获取对我们（唯一）图像的预测
print(np.argmax(predictions_single[0]))
